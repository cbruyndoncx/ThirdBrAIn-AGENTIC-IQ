{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a864294",
   "metadata": {},
   "source": [
    "# Using AutoGen with motleycrew\n",
    "\n",
    "Microsoft AutoGen is one of the most popular multi-agent frameworks. Motleycrew supports interaction with autogen in both directions: firstly, you can wrap an AutoGen chat as a motleycrew tool, which you can then give to any supported agent; secondly, you can give any motleycrew tool (which includes agents used as tools) to an AutoGen agent. \n",
    "\n",
    "The two options are described in detail below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6602c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888adcb2",
   "metadata": {},
   "source": [
    "## Integrating an AutoGen chat into motleycrew\n",
    "\n",
    "If you want to use an AutoGen chat (say one from their many wonderful examples, or one you have already) as part of a motleycrew setup, you can wrap it as a tool, which you can then give to any other motleycrew-supported agent.\n",
    "\n",
    "Let's create an AutoGen chat for automatic problem solving.\n",
    "The code is taken from the example here: https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3da0bc-d0f6-4f9c-8e69-0ad126f3a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyautogen\n",
    "import autogen\n",
    "import os\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [{\"model\": \"gpt-4-turbo\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}],\n",
    "    \"cache_seed\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f7738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 2,\n",
    "        \"work_dir\": \"examples/data/groupchat\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8480361",
   "metadata": {},
   "source": [
    "If we were using plain AutoGen, we'd start the chat with something like this:\n",
    "```\n",
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
    ")\n",
    "```\n",
    "\n",
    "You see, the chat accepts an input and returns an output, just like a tool.  \n",
    "Because of that, for using the chat in motleycrew, we can utilize the built-in AutoGenChatTool. Its prompt can either be a template or a plain string. Here we are creating a tool that searches arXiv for recent papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d610dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from motleycrew.tools.autogen_chat_tool import AutoGenChatTool\n",
    "\n",
    "knowledge_retrieval_tool = AutoGenChatTool(\n",
    "    name=\"retrieve_knowledge_by_topic\",\n",
    "    description=\"Search arxiv for the latest paper on a given topic \"\n",
    "                \"and find its potential applications in software.\",  # will be used in the prompt of the future agent that will use the tool\n",
    "    prompt=\"Find a latest paper about {topic} on arxiv \"\n",
    "            \"and find its potential applications in software.\",  # this is the initial prompt for the AutoGen chat itself\n",
    "    initiator=user_proxy,\n",
    "    recipient=manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580e262",
   "metadata": {},
   "source": [
    "We can now give the tool to any agent and solve tasks with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534453a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from motleycrew import MotleyCrew\n",
    "from motleycrew.agents.langchain.tool_calling_react import ReActToolCallingAgent\n",
    "\n",
    "crew = MotleyCrew()\n",
    "writer = ReActToolCallingAgent(tools=[knowledge_retrieval_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d9d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from motleycrew.tasks import SimpleTask\n",
    "\n",
    "blog_post_task = SimpleTask(\n",
    "        crew = crew,\n",
    "        name=\"Produce blog post on the applications of latest advancements related to GPT-4\",\n",
    "        description=\"Using the insights provided by searching research papers, develop an engaging blog \"\n",
    "                    \"post that highlights the most significant advancements on GPT-4 ant their applications.\\n\"\n",
    "                    \"Your post should be informative yet accessible, catering to a tech-savvy audience.\\n\"\n",
    "                    \"Make it sound cool, avoid complex words so it doesn't sound like AI. \"\n",
    "                    \"Create a blog post of at least 4 paragraphs.\",\n",
    "        agent=writer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0c1a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No known Cypher type matching annotation typing.Optional[typing.Any], will use JSON string\n",
      "WARNING:root:No known Cypher type matching annotation typing.List[str], will use JSON string\n",
      "WARNING:root:No known Cypher type matching annotation typing.List[str], will use JSON string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about GPT-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "First, we'll search the ArXiv repository for the latest papers on GPT-4. We can achieve this using the `arxiv` Python package, which allows querying and fetching papers from ArXiv. \n",
      "\n",
      "To begin, we need to search for the most recent papers related to \"GPT-4\". Once we find the papers, I will look into the one that is most recent and check its content to find mentions of potential applications in software.\n",
      "\n",
      "Let's start by finding the latest paper about GPT-4 on ArXiv:\n",
      "\n",
      "```python\n",
      "# Install the arXiv package if needed\n",
      "# pip install arxiv\n",
      "\n",
      "import arxiv\n",
      "\n",
      "# Query for the latest papers on GPT-4\n",
      "def find_latest_gpt4_paper():\n",
      "    search = arxiv.Search(\n",
      "        query=\"GPT-4\",\n",
      "        max_results=1,\n",
      "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
      "    )\n",
      "    \n",
      "    # Fetch the most recent paper\n",
      "    for result in search.results():\n",
      "        print(\"Title:\", result.title)\n",
      "        print(\"Authors:\", \", \".join(author.name for author in result.authors))\n",
      "        print(\"Abstract:\", result.summary.replace('\\n', ' '))\n",
      "        print(\"Published:\", result.published.date())\n",
      "        print(\"URL:\", result.entry_id)\n",
      "        break\n",
      "\n",
      "find_latest_gpt4_paper()\n",
      "```\n",
      "\n",
      "Please run the above Python script. It will output the title, authors, abstract, publication date, and URL of the most recent paper about GPT-4 on ArXiv. We can then analyze the abstract to identify its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 4, in <module>\n",
      "    import arxiv\n",
      "ModuleNotFoundError: No module named 'arxiv'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "It looks like the Python package `arxiv` is not installed, which caused the error. Instead of using the `arxiv` package, we can employ web scraping techniques to obtain the information from the ArXiv website. We'll use `requests` to fetch the page content and `BeautifulSoup` to parse it.\n",
      "\n",
      "Please ensure that you have the `requests` and `beautifulsoup4` libraries installed. If not, you can install them using pip.\n",
      "\n",
      "Here is the modified code to search for the latest GPT-4 paper on ArXiv using web scraping:\n",
      "\n",
      "```python\n",
      "# filename: fetch_latest_gpt4_paper.py\n",
      "\n",
      "# Install the necessary packages if they are not installed\n",
      "# pip install requests beautifulsoup4\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def fetch_latest_gpt4_paper():\n",
      "    # URL to search for GPT-4 related papers sorted by newest\n",
      "    url = \"https://arxiv.org/search/?query=GPT-4&searchtype=all&abstracts=show&order=-announced_date_first&size=1\"\n",
      "    \n",
      "    # Issue a GET request to fetch the page content\n",
      "    response = requests.get(url)\n",
      "    if response.status_code != 200:\n",
      "        print(\"Failed to fetch data from arXiv\")\n",
      "        return\n",
      "    \n",
      "    # Use BeautifulSoup to parse the HTML content\n",
      "    soup = BeautifulSoup(response.text, 'html.parser')\n",
      "    \n",
      "    # Locate the title, authors, abstract, published date, and link to the paper\n",
      "    paper = soup.select_one('li.arxiv-result')\n",
      "    title = paper.select_one('p.title').text.strip()\n",
      "    authors = paper.select_one('p.authors').text.replace('\\n', ' ').strip()\n",
      "    abstract = paper.select_one('span.abstract-full').text.strip()\n",
      "    published_date = paper.select_one('p.is-size-7').text.strip()\n",
      "    link = \"https://arxiv.org\" + paper.select_one('p.title').a['href']\n",
      "\n",
      "    # Print the results\n",
      "    print(\"Title:\", title)\n",
      "    print(\"Authors:\", authors)\n",
      "    print(\"Abstract:\", abstract)\n",
      "    print(\"Published:\", published_date)\n",
      "    print(\"URL:\", link)\n",
      "\n",
      "fetch_latest_gpt4_paper()\n",
      "```\n",
      "\n",
      "Please save this script to a file, install the required packages if needed, and run the script. It will print the details of the most recent paper on GPT-4 from ArXiv. We can then proceed to analyze the abstract for potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Failed to fetch data from arXiv\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there was an issue fetching the data from the ArXiv website, possibly due to network issues or restrictions on scraping from their site. As an alternative approach, here are some methods you can consider to manually find the latest paper about GPT-4 on ArXiv:\n",
      "\n",
      "### Manual Search on ArXiv:\n",
      "1. **Go to the ArXiv website**: Visit [arxiv.org](https://arxiv.org/).\n",
      "2. **Use the Search Bar**: Type \"GPT-4\" into the search bar.\n",
      "3. **Adjust Search Settings**: Ensure the search is set to sort by the most recent submissions first. You can adjust this in the search settings.\n",
      "4. **Review Results**: Look through the titles and abstracts for the most recent entries to find relevant papers.\n",
      "\n",
      "### Google Scholar:\n",
      "1. **Visit Google Scholar**: Go to [Google Scholar](https://scholar.google.com/).\n",
      "2. **Search for \"GPT-4\"**: Ensure to add filters for recent years to get the most up-to-date research.\n",
      "3. **Review and Filter Results**: Google Scholar often includes links to ArXiv preprints, helping you find the latest studies.\n",
      "\n",
      "### Using APIs:\n",
      "If you are still interested in automating this process, using a more robust method such as the CrossRef API or the ArXiv API with proper handling of user-agent and headers might yield better results.\n",
      "\n",
      "If you can manually find a paper, you can share its abstract here, and we can analyze potential software applications together. Alternatively, if you have any other tasks or need further assistance, feel free to let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about GPT-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "First, let's write a script to search for the latest papers about GPT-4 on arXiv, a well-known repository for scientific papers. The script will use the arXiv API to fetch this information. Let's retrieve the details of the most recent paper related to GPT-4.\n",
      "\n",
      "```python\n",
      "# filename: fetch_gpt4_papers.py\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "# Define the base URL for the ArXiv API\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Specify search parameters: search for GPT-4, max result is 1, sorted by the latest submissions\n",
      "search_params = {\n",
      "    \"search_query\": \"all:GPT-4\",\n",
      "    \"sortBy\": \"submittedDate\",\n",
      "    \"sortOrder\": \"descending\",\n",
      "    \"max_results\": 1\n",
      "}\n",
      "\n",
      "# Encode the search parameters, make the request, and read the response\n",
      "query_string = urllib.parse.urlencode(search_params)\n",
      "search_url = base_url + query_string\n",
      "response = urllib.request.urlopen(search_url)\n",
      "response_content = response.read()\n",
      "\n",
      "# Parse the XML response content\n",
      "root = ET.fromstring(response_content)\n",
      "\n",
      "# Extract and print the title, summary, and published date from the entry\n",
      "for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
      "    title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
      "    summary = entry.find('{http://www.w3.org/2005/Atom}summary').text\n",
      "    published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
      "\n",
      "    # Output the results\n",
      "    print('Title:', title)\n",
      "    print('Published Date:', published_date)\n",
      "    print('Summary:', summary)\n",
      "```\n",
      "\n",
      "**Instructions**: \n",
      "1. Save the above script to a file named `fetch_gpt4_papers.py`.\n",
      "2. Run the script using a Python interpreter. This will retrieve the latest paper about GPT-4 from arXiv.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Title: Observational Scaling Laws and the Predictability of Language Model\n",
      "  Performance\n",
      "Published Date: 2024-05-17T17:49:44Z\n",
      "Summary:   Understanding how language model performance varies with scale is critical to\n",
      "benchmark and algorithm development. Scaling laws are one approach to building\n",
      "this understanding, but the requirement of training models across many\n",
      "different scales has limited their use. We propose an alternative,\n",
      "observational approach that bypasses model training and instead builds scaling\n",
      "laws from ~80 publically available models. Building a single scaling law from\n",
      "multiple model families is challenging due to large variations in their\n",
      "training compute efficiencies and capabilities. However, we show that these\n",
      "variations are consistent with a simple, generalized scaling law where language\n",
      "model performance is a function of a low-dimensional capability space, and\n",
      "model families only vary in their efficiency in converting training compute to\n",
      "capabilities. Using this approach, we show the surprising predictability of\n",
      "complex scaling phenomena: we show that several emergent phenomena follow a\n",
      "smooth, sigmoidal behavior and are predictable from small models; we show that\n",
      "the agent performance of models such as GPT-4 can be precisely predicted from\n",
      "simpler non-agentic benchmarks; and we show how to predict the impact of\n",
      "post-training interventions like Chain-of-Thought and Self-Consistency as\n",
      "language model capabilities continue to improve.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Based on the summary of the latest paper about GPT-4 titled \"Observational Scaling Laws and the Predictability of Language Model Performance,\" here are several potential applications in software development and related fields:\n",
      "\n",
      "1. **Predictive Benchmarking Tools**:\n",
      "   - The paper discusses the predictability of language model performance using scaling laws. This could lead to the development of new software tools that predict the performance of language models like GPT-4 based on various scaling inputs. Such tools would be valuable in optimizing model configurations for specific applications without needing extensive empirical testing.\n",
      "\n",
      "2. **Resource Optimization Algorithms**:\n",
      "   - The paper's framework for predicting performance as a function of a \"capability space\" can be translated into algorithms that optimize the training compute resources for developing AI models. This could significantly reduce costs and increase the efficiency of AI training cycles in commercial software development.\n",
      "\n",
      "3. **Automated Model Scaling**:\n",
      "   - Software that automatically scales AI models' capabilities based on available compute resources could be developed. This would make AI more accessible, especially for organizations with fluctuating resource availability, by providing them with tools to dynamically adjust their model's complexity and performance.\n",
      "\n",
      "4. **Advanced Development Frameworks**:\n",
      "   - Integrating the predictive scaling laws into AI development frameworks could enable developers to anticipate the behavior and limitations of their models, facilitating more accurate and robust AI systems design.\n",
      "\n",
      "5. **Enhanced Debugging and Analysis Tools**:\n",
      "   - Using the generalized scaling law proposed in the paper, new debugging and performance analysis tools can be created, which would help in identifying bottlenecks and inefficiencies in language model training and operation.\n",
      "\n",
      "6. **Optimization of Intervention Techniques**:\n",
      "   - The ability to predict the impact of post-training interventions like the Chain-of-Thought and Self-Consistency could be encapsulated in software solutions that optimize these interventions. This would improve the effectiveness and reliability of language models in practical applications.\n",
      "\n",
      "These applications demonstrate how theoretical insights from academic research can be used to inform and enhance software product development, particularly in the rapidly evolving field of artificial intelligence.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No known Cypher type matching annotation typing.Optional[typing.Any], will use JSON string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Task(status=done)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crew.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae5789a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Final Answer: Welcome to the Future: Exploring the Frontiers of GPT-4\n",
       "\n",
       "In the rapidly evolving world of artificial intelligence, GPT-4 stands out as a beacon of innovation and potential. Recent research, particularly a fascinating study titled \"Observational Scaling Laws and the Predictability of Language Model Performance,\" sheds light on groundbreaking advancements that could redefine how we interact with technology.\n",
       "\n",
       "GPT-4 isn't just about understanding or generating text; it's about predicting and optimizing performance in ways previously deemed impossible. The study introduces predictive benchmarking tools that could revolutionize the development of AI models. Imagine software that can anticipate the performance of language models like GPT-4 based on various inputs, streamlining the development process and enhancing efficiency without the need for extensive testing.\n",
       "\n",
       "But the implications extend beyond mere prediction. The research discusses resource optimization algorithms that could significantly reduce the costs associated with AI training. These algorithms utilize a \"capability space\" to optimize the compute resources needed, ensuring that AI development is not only faster but also more economical.\n",
       "\n",
       "Moreover, GPT-4 could lead to the creation of automated model scaling software. Such tools would adjust AI capabilities based on available resources, making cutting-edge technology accessible to a broader range of users and organizations, regardless of their fluctuating resource availability.\n",
       "\n",
       "The integration of these advancements into AI development frameworks could also empower developers with better tools for debugging and performance analysis, enhancing the robustness and accuracy of AI systems. This is not just about making AI smarter; it's about making AI development smarter, more intuitive, and infinitely more creative.\n",
       "\n",
       "As we stand on the brink of these exciting developments, GPT-4 is not just a tool but a transformational force in the tech landscape, promising to bring about a new era of innovation and efficiency. Stay tuned, because the future of AI is here, and it's more promising than ever!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(blog_post_task.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c5eb1",
   "metadata": {},
   "source": [
    "The writer agent used the AutoGen chat tool to retrieve data for the post!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf1868-9567-4240-b7e3-d5f6a50d3974",
   "metadata": {},
   "source": [
    "## Using any motleycrew-supported tools with Autogen agents\n",
    "\n",
    "Now let's do it the other way around: give tools (or agents, for that matter) from motleycrew to AutoGen agents. The code is based on https://microsoft.github.io/autogen/docs/tutorial/tool-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a79da460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function motleycrew.tools.tool.MotleyTool.to_autogen_tool.<locals>.autogen_tool_fn(input: str) -> str>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from motleycrew.tools import MotleyTool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = MotleyTool.from_supported_tool(DuckDuckGoSearchRun())  # Any tools or even motleycrew's agents can be converted to MotleyTool like this!\n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = autogen.ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can provide useful and up-to-date data using web search. \"\n",
    "    \"Return 'TERMINATE' when the task is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Make an autogen-compatible tool from the MotleyTool.\n",
    "autogen_tool = search_tool.to_autogen_tool()\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "assistant.register_for_llm(name=\"search_tool\", description=\"Web search tool\")(autogen_tool)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"search_tool\")(autogen_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6027c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What was the first computer?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_Na0NhkbZVtS7cnme7XRqxqUS): search_tool *****\u001b[0m\n",
      "Arguments: \n",
      "{\"input\":\"first computer\"}\n",
      "\u001b[32m****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_tool...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_Na0NhkbZVtS7cnme7XRqxqUS) *****\u001b[0m\n",
      "ENIAC, the first programmable general-purpose electronic digital computer, built during World War II by the United States and completed in 1946. The project was led by John Mauchly, J. Presper Eckert, Jr., and their colleagues. ENIAC was the most powerful calculating device built to that time. Learn about the origins and evolution of computers, from the first mechanical and electric machines to the modern devices we use today. Explore the inventions, concepts, and events that shaped the computer industry and culture. Learn about the history of computing, from Charles Babbage's mechanical difference and analytical engines to the first electronic computer, the Atanasoff-Berry Computer. Discover how World War II and personal computers shaped the evolution of computing. The first commercially available personal computer was the Altair 8800, released in 1975. The Altair was a rudimentary device sold as a $439 kit that users had to assemble themselves, but it quickly gained a cult following among technology enthusiasts. Ada Lovelace, English mathematician, an associate of Charles Babbage, for whose digital computer prototype, the Analytical Engine, she created a program in 1843. She has been called the first computer programmer. Ada Lovelace Day, the second Tuesday in October, honors women's contributions to science and technology.\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "The first programmable general-purpose electronic digital computer was the ENIAC, completed in 1946. It was built during World War II by the United States and led by John Mauchly, J. Presper Eckert, Jr., and their colleagues. ENIAC stood as the most powerful calculating device of its time.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant, message=\"What was the first computer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = chat_result.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f444f",
   "metadata": {},
   "source": [
    "The agent used the search tool!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
